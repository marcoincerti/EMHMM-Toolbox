{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcoincerti/EMHMM-Toolbox/blob/main/emhmm_toolbox_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.special import logsumexp\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MWii2pOR4l3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_path):\n",
        "    print(f'Reading {file_path}')\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Get the headers\n",
        "    headers = df.columns.tolist()\n",
        "\n",
        "    # Find the header indices\n",
        "    SID = headers.index('SubjectID')\n",
        "    TID = headers.index('TrialID')\n",
        "    FX = headers.index('FixX')\n",
        "    FY = headers.index('FixY')\n",
        "    FD = headers.index('FixD') if 'FixD' in headers else None\n",
        "\n",
        "    # Check if required headers exist\n",
        "    if SID == -1:\n",
        "        raise ValueError('Error with SubjectID')\n",
        "    print(f'- found SubjectID in column {SID + 1}')\n",
        "\n",
        "    if TID == -1:\n",
        "        raise ValueError('Error with TrialID')\n",
        "    print(f'- found TrialID in column {TID + 1}')\n",
        "\n",
        "    if FX == -1:\n",
        "        raise ValueError('Error with FixX')\n",
        "    print(f'- found FixX in column {FX + 1}')\n",
        "\n",
        "    if FY == -1:\n",
        "        raise ValueError('Error with FixY')\n",
        "    print(f'- found FixY in column {FY + 1}')\n",
        "\n",
        "    if FD is not None:\n",
        "        print(f'- found FixD in column {FD + 1}')\n",
        "\n",
        "    # Initialize data structures\n",
        "    sid_names = []\n",
        "    sid_trials = []\n",
        "    data = []\n",
        "\n",
        "    # Read data\n",
        "    for _, row in df.iterrows():\n",
        "        mysid = str(int(row[SID])) if np.issubdtype(type(row[SID]), np.number) else str(row[SID])\n",
        "        mytid = str(int(row[TID])) if np.issubdtype(type(row[TID]), np.number) else str(row[TID])\n",
        "        myfxy = [row[FX], row[FY]]\n",
        "\n",
        "        if FD is not None:\n",
        "            myfxy.append(row[FD])\n",
        "\n",
        "        # Find subject\n",
        "        s = sid_names.index(mysid) if mysid in sid_names else -1\n",
        "        if s == -1:\n",
        "            # New subject\n",
        "            sid_names.append(mysid)\n",
        "            sid_trials.append([])\n",
        "            data.append([])\n",
        "\n",
        "        # Find trial\n",
        "        t = -1\n",
        "        if s != -1:\n",
        "            t = sid_trials[s].index(mytid) if mytid in sid_trials[s] else -1\n",
        "        if t == -1:\n",
        "            sid_trials[s].append(mytid)\n",
        "            data[s].append([])\n",
        "\n",
        "        # Put fixation\n",
        "        data[s][t].append(myfxy)\n",
        "\n",
        "    print(f'- found {len(sid_names)} subjects:')\n",
        "    print(' '.join(sid_names))\n",
        "\n",
        "    for i, subject in enumerate(data):\n",
        "        print(f'  * subject {i + 1} had {len(subject)} trials')\n",
        "\n",
        "    return data, sid_names, sid_trials\n",
        "\n",
        "file_path = '/content/demodata.xls'\n",
        "data, sid_names, sid_trials = read_data(file_path)"
      ],
      "metadata": {
        "id": "lnHjqNqZSLeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening the array\n",
        "flattened_array = [element for sublist in data[0] for element in sublist]\n",
        "\n",
        "d = np.array(flattened_array)\n",
        "\n"
      ],
      "metadata": {
        "id": "mpNhycpM7KZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install hmmlearn"
      ],
      "metadata": {
        "id": "8H8bj1uELNY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse\n",
        "from hmmlearn import hmm, vhmm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "fixation_data = d  # 2D fixation coordinates\n",
        "\n",
        "# Load the image\n",
        "img = mpimg.imread('/content/face.jpg')  # Replace 'path_to_your_image_file.jpg' with the actual image file path\n",
        "\n",
        "# Define the number of hidden states for the HMM\n",
        "n_states = 3\n",
        "\n",
        "'''\n",
        "\"full\": Assumes a full covariance matrix for each hidden state. This means each state can have a different covariance structure.\n",
        "\"diag\": Assumes a diagonal covariance matrix for each hidden state. This means each state has its own variances but no covariance between dimensions.\n",
        "\"spherical\": Assumes a single variance value for each hidden state. This means each state has a spherical covariance, where the variances are the same for all dimensions.\n",
        "'''\n",
        "\n",
        "# Create an HMM model with the specified covariance type and initialization method\n",
        "'''\n",
        "model = hmm.GaussianHMM(n_components=n_states,\n",
        "                        covariance_type=covariance_type,\n",
        "                        init_params=init_method,\n",
        "                        n_iter=100,\n",
        "                        verbose=True)\n",
        "'''\n",
        "#model = hmm.GMMHMM(n_components=n_states, random_state=42)\n",
        "\n",
        "model = vhmm.VariationalGaussianHMM(n_components=n_states, random_state=42, algorithm='viterbi')\n",
        "\n",
        "# Fit the HMM to the fixation data using the EM algorithm\n",
        "model.fit(fixation_data)\n",
        "\n",
        "# Generate a scanpath using the trained HMM\n",
        "scanpath, _ = model.sample(len(fixation_data))\n",
        "\n",
        "# Retrieve the estimated parameters after training\n",
        "estimated_means = model.means_\n",
        "estimated_covariances = model.covars_\n",
        "estimated_transition_matrix = model.transmat_\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated Means:\")\n",
        "print(estimated_means)\n",
        "print(\"Estimated Covariance Matrices:\")\n",
        "print(estimated_covariances)\n",
        "print(\"Estimated Transition Matrix:\")\n",
        "print(estimated_transition_matrix)\n",
        "\n",
        "# Calculate the log-likelihood of the generated scanpath\n",
        "log_likelihood = model.score(scanpath)\n",
        "\n",
        "# Plot the original fixation data and the generated scanpath\n",
        "plt.plot(fixation_data[:, 0], fixation_data[:, 1], 'ro-', label='Fixation Data')\n",
        "#plt.plot(scanpath[:, 0], scanpath[:, 1], 'bo-', label='Generated Scanpath')\n",
        "plt.imshow(img)  # Replace xmin, xmax, ymin, ymax with the appropriate plot limits\n",
        "\n",
        "\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.title('Scanpath (Log-Likelihood: {:.2f})'.format(log_likelihood))\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the sampled data\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(fixation_data[:, 0], fixation_data[:, 1], \".-\", label=\"observations\", ms=6,\n",
        "        mfc=\"orange\", alpha=0.7)\n",
        "\n",
        "means = model.means_\n",
        "# Indicate the component numbers\n",
        "for i, m in enumerate(means):\n",
        "    ax.text(m[0], m[1], 'Component %i' % (i + 1),\n",
        "            size=5, horizontalalignment='center',\n",
        "            bbox=dict(alpha=.7, facecolor='w'))\n",
        "ax.legend(loc='best')\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# Get the state probabilities for each fixation\n",
        "state_probabilities = model.predict_proba(fixation_data)\n",
        "\n",
        "# Set up colors or marker styles based on state probabilities\n",
        "colors = state_probabilities.argmax(axis=1)  # Use the state with the highest probability as color index\n",
        "markers = ['o', 's', '^']  # Specify marker styles for each state\n",
        "\n",
        "# Plot the fixation clusters\n",
        "for state in range(model.n_components):\n",
        "    # Get the fixations belonging to the current state\n",
        "    state_fixations = fixation_data[colors == state]\n",
        "\n",
        "    # Plot the fixations with the corresponding color and marker style\n",
        "    plt.scatter(state_fixations[:, 0],\n",
        "                state_fixations[:, 1],\n",
        "                color='C{}'.format(state),\n",
        "                marker=markers[state],\n",
        "                label=f'State {state}')\n",
        "\n",
        "# Add legend and labels to the plot\n",
        "plt.legend()\n",
        "plt.xlabel('X-coordinate')\n",
        "plt.ylabel('Y-coordinate')\n",
        "\n",
        "# Show the plot\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "'''\n",
        "# Assign colors to clusters\n",
        "colors = ['red', 'blue', 'green']  # Add more colors if needed\n",
        "\n",
        "# Plot the fixation data, means, and ellipses\n",
        "plt.scatter(fixation_data[:, 0], fixation_data[:, 1], c=model.predict(fixation_data), cmap=plt.cm.get_cmap('jet', n_states), label='Fixation Data')\n",
        "plt.scatter(estimated_means[:, 0], estimated_means[:, 1], c=range(n_states), cmap=plt.cm.get_cmap('jet', n_states), marker='x', label='State Means')\n",
        "\n",
        "if n_states == 2:\n",
        "    # Plot the fixation data, state means, and state boundaries\n",
        "    plt.scatter(fixation_data[:, 0], fixation_data[:, 1], c=model.predict(fixation_data), cmap=plt.cm.get_cmap('jet', n_states), label='Fixation Data')\n",
        "    plt.scatter(estimated_means[:, 0], estimated_means[:, 1], c=range(n_states), cmap=plt.cm.get_cmap('jet', n_states), marker='x', label='State Means')\n",
        "\n",
        "    for i in range(n_states):\n",
        "        cov_matrix = estimated_covariances[i]  # Full covariance matrix\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "        angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))  # Extract angle from eigenvectors\n",
        "        width = 2 * np.sqrt(2 * eigenvalues[0])\n",
        "        height = 2 * np.sqrt(2 * eigenvalues[1])\n",
        "        ellipse = Ellipse(xy=estimated_means[i], width=width, height=height, angle=angle, edgecolor=colors[i], facecolor='none')\n",
        "        plt.gca().add_patch(ellipse)\n",
        "else:\n",
        "    # Plot the fixation data, cluster means, and cluster boundaries\n",
        "    plt.scatter(fixation_data[:, 0], fixation_data[:, 1], c=model.predict(fixation_data), cmap=plt.cm.get_cmap('jet', n_states), label='Fixation Data')\n",
        "    plt.scatter(estimated_means[:, 0], estimated_means[:, 1], c=range(n_states), cmap=plt.cm.get_cmap('jet', n_states), marker='x', label='State Means')\n",
        "\n",
        "    for i in range(n_states):\n",
        "        cov_matrix = estimated_covariances[i]  # Full covariance matrix\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "        angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))  # Extract angle from eigenvectors\n",
        "        width = 2 * np.sqrt(2 * eigenvalues[0])\n",
        "        height = 2 * np.sqrt(2 * eigenvalues[1])\n",
        "        ellipse = Ellipse(xy=estimated_means[i], width=width, height=height, angle=angle, edgecolor=colors[i], facecolor='none')\n",
        "        plt.gca().add_patch(ellipse)\n",
        "\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.title('Fixation Data Clustering')\n",
        "plt.imshow(img)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "'''\n"
      ],
      "metadata": {
        "id": "ncrrmbUnN3xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "np.set_printoptions(formatter={'float_kind': \"{:.3f}\".format})\n",
        "rs = check_random_state(42)\n",
        "sample_length = len(d)\n",
        "# With random initialization, it takes a few tries to find the\n",
        "# best solution\n",
        "num_inits = 5\n",
        "num_states = np.arange(2, 4)\n",
        "verbose = False\n",
        "fixation_data = d\n",
        "sequences = np.asarray(fixation_data)\n",
        "#({\"spherical\", \"diag\", \"full\", \"tied\"}, optional)\n",
        "covariance_type = \"diag\"\n",
        "#({\"viterbi\", \"map\"}, optional)\n",
        "algorithm = \"viterbi\"\n",
        "# {\"log\",\"scaling\"}\n",
        "implementation = \"log\"\n",
        "\n",
        "# Train a suite of models, and keep track of the best model for each\n",
        "# number of states, and algorithm\n",
        "best_scores = collections.defaultdict(dict)\n",
        "best_models = collections.defaultdict(dict)\n",
        "for n in num_states:\n",
        "    for i in range(num_inits):\n",
        "        vi = vhmm.VariationalGaussianHMM(n,\n",
        "                                         n_iter=1000,\n",
        "                                         covariance_type=covariance_type,\n",
        "                                         implementation=implementation,\n",
        "                                         tol=1e-6,\n",
        "                                         random_state=rs,\n",
        "                                         verbose=verbose)\n",
        "        vi.fit(sequences, [sample_length])\n",
        "        lb = vi.monitor_.history[-1]\n",
        "        print(f\"Training VI({n}) Variational Lower Bound={lb} \"\n",
        "              f\"Iterations={len(vi.monitor_.history)} \")\n",
        "        if best_models[\"VI\"].get(n) is None or best_scores[\"VI\"][n] < lb:\n",
        "            best_models[\"VI\"][n] = vi\n",
        "            best_scores[\"VI\"][n] = lb\n",
        "\n",
        "        em = hmm.GMMHMM(n,\n",
        "                        n_iter=1000,\n",
        "                        covariance_type=covariance_type,\n",
        "                        implementation=implementation,\n",
        "                        tol=1e-6,\n",
        "                        random_state=rs,\n",
        "                        verbose=verbose)\n",
        "        em.fit(sequences, [sample_length])\n",
        "        ll = em.monitor_.history[-1]\n",
        "        print(f\"Training EM({n}) Final Log Likelihood={ll} \"\n",
        "              f\"Iterations={len(vi.monitor_.history)} \")\n",
        "        if best_models[\"EM\"].get(n) is None or best_scores[\"EM\"][n] < ll:\n",
        "            best_models[\"EM\"][n] = em\n",
        "            best_scores[\"EM\"][n] = ll\n",
        "\n",
        "# Display the model likelihood/variational lower bound for each N\n",
        "# and show the best learned model\n",
        "\n",
        "bestModel = None\n",
        "for algo, scores in best_scores.items():\n",
        "    best = max(scores.values())\n",
        "    best_n, best_score = max(scores.items(), key=lambda x: x[1])\n",
        "    for n, score in scores.items():\n",
        "        flag = \"* <- Best Model\" if score == best_score else \"\"\n",
        "        print(f\"{algo}({n}): {score:.4f}{flag}\")\n",
        "\n",
        "    print(f\"Best Model {algo}\")\n",
        "    bestModel = best_models[algo][best_n]\n",
        "    print(bestModel.transmat_)\n",
        "    print(bestModel.means_)\n",
        "    print(bestModel.covars_)\n",
        "\n",
        "    scanpath, _ = bestModel.sample(len(fixation_data))\n",
        "    # Calculate the log-likelihood of the generated scanpath\n",
        "    log_likelihood = bestModel.score(scanpath)\n",
        "    print(f\"n_componets: {bestModel.n_components}, ll: {log_likelihood}\")\n"
      ],
      "metadata": {
        "id": "S_rUY1VdOBrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the original fixation data and the generated scanpath\n",
        "plt.plot(fixation_data[:, 0], fixation_data[:, 1], 'ro-', label='Fixation Data')\n",
        "plt.plot(scanpath[:, 0], scanpath[:, 1], 'bo-', label='Generated Scanpath')\n",
        "plt.imshow(img)  # Replace xmin, xmax, ymin, ymax with the appropriate plot limits\n",
        "\n",
        "\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.title('Scanpath (Log-Likelihood: {:.2f})'.format(log_likelihood))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bx2k4o2LXeSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = hmm.GaussianHMM(3, init_params=\"stc\")\n",
        "model.n_features = 3\n",
        "#model.startprob_ = np.array([1/4., 1/4., 1/4., 1/4.])\n",
        "'''\n",
        "model.transmat_ = np.array([[0.3, 0.4, 0.2, 0.1],\n",
        "                            [0.1, 0.2, 0.3, 0.4],\n",
        "                            [0.5, 0.2, 0.1, 0.2],\n",
        "                            [0.25, 0.25, 0.25, 0.25]])\n",
        "'''\n",
        "model.means_ = np.array([[-2.5], [0], [2.5], [5.]])\n",
        "#model.covars_ = np.sqrt([[0.25], [0.25], [0.25], [0.25]])\n",
        "\n",
        "X, _ = model.sample(1000, random_state=rs)\n",
        "lengths = [X.shape[0]]\n",
        "\n",
        "aic = []\n",
        "bic = []\n",
        "lls = []\n",
        "ns = [2, 3]\n",
        "for n in ns:\n",
        "    best_ll = None\n",
        "    best_model = None\n",
        "    for i in range(10):\n",
        "        h = hmm.GaussianHMM(n, n_iter=200, tol=1e-4, random_state=rs)\n",
        "        h.fit(X)\n",
        "        score = h.score(X)\n",
        "        if not best_ll or best_ll < best_ll:\n",
        "            best_ll = score\n",
        "            best_model = h\n",
        "    aic.append(best_model.aic(X))\n",
        "    bic.append(best_model.bic(X))\n",
        "    lls.append(best_model.score(X))\n"
      ],
      "metadata": {
        "id": "_3wOq09eP9eZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}